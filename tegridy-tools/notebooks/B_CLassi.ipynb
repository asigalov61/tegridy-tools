{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# B CLassi (ver. 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2023\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "ePWjo4hLkSZh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1H5U8iiAIgD"
      },
      "source": [
        "# (SETUP ENVIRONMENT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "\n",
        "!git clone https://github.com/asigalov61/B-CLassi\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "8Dt7FYceaCKF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading needed modules. Please wait...')\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import statistics\n",
        "import random\n",
        "\n",
        "import shutil\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from joblib import Parallel, delayed, parallel_config\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('=' * 70)\n",
        "print('Creating I/O dirs...')\n",
        "\n",
        "if not os.path.exists('/content/GOOD'):\n",
        "    os.makedirs('/content/GOOD')\n",
        "\n",
        "if not os.path.exists('/content/BAD'):\n",
        "    os.makedirs('/content/BAD')\n",
        "\n",
        "if not os.path.exists('/content/EVAL_IN'):\n",
        "    os.makedirs('/content/EVAL_IN')\n",
        "\n",
        "if not os.path.exists('/content/EVAL_OUT'):\n",
        "    os.makedirs('/content/EVAL_OUT')\n",
        "\n",
        "if not os.path.exists('/content/EVAL_OUT/GOOD'):\n",
        "    os.makedirs('/content/EVAL_OUT/GOOD')\n",
        "\n",
        "if not os.path.exists('/content/EVAL_OUT/BAD'):\n",
        "    os.makedirs('/content/EVAL_OUT/BAD')\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading TMIDIX module...')\n",
        "\n",
        "%cd /content/B-CLassi/\n",
        "\n",
        "import TMIDIX\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading Tensorflow module...')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "tf.config.list_physical_devices('GPU')\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('Enjoy! :)')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Lqp3urZyaDAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (DOWNLOAD MIDI DATASET)"
      ],
      "metadata": {
        "id": "qorGIiU7GshG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Donwload and unzip sample MIDI classification dataset\n",
        "%cd /content/\n",
        "!wget https://github.com/asigalov61/Tegridy-MIDI-Dataset/raw/master/B-CLassi-MIDI-Dataset-CC-BY-NC-SA.zip\n",
        "!unzip B-CLassi-MIDI-Dataset-CC-BY-NC-SA.zip\n",
        "!rm B-CLassi-MIDI-Dataset-CC-BY-NC-SA.zip\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "Vt-mFojtGtwI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (LOAD MIDI PROCESSOR)"
      ],
      "metadata": {
        "id": "Mkill3ajck8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TMIDIX MIDI Processor\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading TMIDIX MIDI Processor...')\n",
        "print('=' * 70)\n",
        "\n",
        "def group_single_elements(lst):\n",
        "  new_lst = []\n",
        "  temp = []\n",
        "  for sublist in lst:\n",
        "      if len(sublist) == 1:\n",
        "          temp.extend(sublist)\n",
        "      else:\n",
        "          if temp:\n",
        "              new_lst.append(temp)\n",
        "              temp = []\n",
        "          new_lst.append(sublist)\n",
        "  if temp:\n",
        "      new_lst.append(temp)\n",
        "  return new_lst\n",
        "\n",
        "def TMIDIX_MIDI_Processor(midi_file):\n",
        "\n",
        "    melody_chords = []\n",
        "\n",
        "    try:\n",
        "\n",
        "        fn = os.path.basename(midi_file)\n",
        "\n",
        "        # Filtering out GIANT4 MIDIs\n",
        "        file_size = os.path.getsize(midi_file)\n",
        "\n",
        "        if file_size <= 1000000:\n",
        "\n",
        "          #=======================================================\n",
        "          # START PROCESSING\n",
        "\n",
        "          # Convering MIDI to ms score with MIDI.py module\n",
        "          score = TMIDIX.midi2single_track_ms_score(open(midi_file, 'rb').read(), recalculate_channels=False)\n",
        "\n",
        "          # INSTRUMENTS CONVERSION CYCLE\n",
        "          events_matrix = []\n",
        "          itrack = 1\n",
        "          patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "          while itrack < len(score):\n",
        "              for event in score[itrack]:\n",
        "                  if event[0] == 'note' or event[0] == 'patch_change':\n",
        "                      events_matrix.append(event)\n",
        "              itrack += 1\n",
        "\n",
        "          events_matrix.sort(key=lambda x: x[1])\n",
        "\n",
        "          events_matrix1 = []\n",
        "\n",
        "          for event in events_matrix:\n",
        "                  if event[0] == 'patch_change':\n",
        "                        patches[event[2]] = event[3]\n",
        "\n",
        "                  if event[0] == 'note':\n",
        "                        event.extend([patches[event[3]]])\n",
        "\n",
        "                        if events_matrix1:\n",
        "                            if (event[1] == events_matrix1[-1][1]):\n",
        "                                if ([event[3], event[4]] != events_matrix1[-1][3:5]):\n",
        "                                    events_matrix1.append(event)\n",
        "                            else:\n",
        "                                events_matrix1.append(event)\n",
        "\n",
        "                        else:\n",
        "                            events_matrix1.append(event)\n",
        "\n",
        "        if len(events_matrix1) > 0:\n",
        "            if min([e[1] for e in events_matrix1]) >= 0 and min([e[2] for e in events_matrix1]) >= 0:\n",
        "\n",
        "                #=======================================================\n",
        "                # PRE-PROCESSING\n",
        "\n",
        "                # checking number of instruments in a composition\n",
        "                instruments_list = list(set([y[3] for y in events_matrix1]))\n",
        "\n",
        "                if len(events_matrix1) > 0:\n",
        "\n",
        "                    #===================================\n",
        "                    # ORIGINAL COMPOSITION\n",
        "                    #===================================\n",
        "\n",
        "                    # Sorting by patch, pitch, then by start-time\n",
        "\n",
        "                    events_matrix1.sort(key=lambda x: x[6])\n",
        "                    events_matrix1.sort(key=lambda x: x[4], reverse=True)\n",
        "                    events_matrix1.sort(key=lambda x: x[1])\n",
        "\n",
        "                    #=======================================================\n",
        "                    # FINAL PROCESSING\n",
        "\n",
        "                    #=======================================================\n",
        "                    # MAIN PROCESSING CYCLE\n",
        "                    #=======================================================\n",
        "\n",
        "                    for e in events_matrix1:\n",
        "\n",
        "                        cha = max(0, min(15, e[3]))\n",
        "\n",
        "                        # Pitches\n",
        "                        if cha == 9: # Drums patch will be == 128\n",
        "                            e[4] = max(1, min(127, e[4]))\n",
        "\n",
        "                        else:\n",
        "                            e[4] = max(1, min(127, e[4]))+128\n",
        "\n",
        "                    events_matrix1.sort(key=lambda x: x[4], reverse=True)\n",
        "                    events_matrix1.sort(key=lambda x: x[1])\n",
        "\n",
        "\n",
        "                    chords = []\n",
        "                    cho = []\n",
        "\n",
        "                    pe = events_matrix1[0]\n",
        "\n",
        "                    for e in events_matrix1:\n",
        "                      if e[1] - pe[1] == 0:\n",
        "                        cho.append(e)\n",
        "                      else:\n",
        "                        if len(cho) > 0:\n",
        "                          chords.append(cho)\n",
        "                        cho = []\n",
        "                        cho.append(e)\n",
        "\n",
        "                      pe = e\n",
        "\n",
        "                    if len(cho) > 0:\n",
        "                      chords.append(cho)\n",
        "\n",
        "                    chords1 = group_single_elements(chords)\n",
        "\n",
        "                    chords2 = []\n",
        "\n",
        "                    for t in chords1:\n",
        "                      if len(t) == 1:\n",
        "                        chords2.extend([256, t[0][4]])\n",
        "\n",
        "                      elif len(t) > 1 and len(list(set([tt[1] for tt in t]))) > 1:\n",
        "                        chords2.extend([256] + [tt[4] for tt in t])\n",
        "\n",
        "                      elif len(t) > 1 and len(list(set([tt[1] for tt in t]))) == 1:\n",
        "                        chords2.extend([257] + [tt[4] for tt in t])\n",
        "\n",
        "                    #=======================================================\n",
        "\n",
        "                    # TOTAL DICTIONARY SIZE 257\n",
        "\n",
        "                    #=======================================================\n",
        "\n",
        "                    return chords2, fn\n",
        "\n",
        "    except:\n",
        "      return None\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "havh3215aI0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (PROCESS GOOD MIDI DATA)"
      ],
      "metadata": {
        "id": "jklH7sqibkaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save file list\n",
        "###########\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/GOOD\"\n",
        "\n",
        "# os.chdir(dataset_addr)\n",
        "filez = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if not filez:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "else:\n",
        "  print('Randomizing file list...')\n",
        "  random.shuffle(filez)\n",
        "  print('Done!')\n",
        "  print('=' * 70)\n",
        "  print('Total files:', len(filez))\n",
        "  print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CWUE991haFP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process MIDIs with TMIDIX MIDI processor\n",
        "\n",
        "print('=' * 70)\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('=' * 70)\n",
        "print('Starting up...')\n",
        "print('=' * 70)\n",
        "\n",
        "###########\n",
        "\n",
        "melody_chords_f = []\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "print('=' * 70)\n",
        "\n",
        "for i in tqdm(range(0, len(filez), 16)):\n",
        "\n",
        "  with parallel_config(backend='threading', n_jobs=4, verbose = 0):\n",
        "\n",
        "    output = Parallel()(delayed(TMIDIX_MIDI_Processor)(f) for f in filez[i:i+16])\n",
        "\n",
        "    for o in output:\n",
        "\n",
        "        if o is not None:\n",
        "            melody_chords_f.append(o)\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QFTjKHcgaaYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (PROCESS BAD MIDI DATA)"
      ],
      "metadata": {
        "id": "7wA_gYiabc-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save file list\n",
        "###########\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/BAD\"\n",
        "\n",
        "# os.chdir(dataset_addr)\n",
        "filez1 = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez1 += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if not filez1:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "else:\n",
        "  print('Randomizing file list...')\n",
        "  random.shuffle(filez1)\n",
        "  print('Done!')\n",
        "  print('=' * 70)\n",
        "  print('Total files:', len(filez1))\n",
        "  print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "V3V0dDs-cg8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process MIDIs with TMIDIX MIDI processor\n",
        "\n",
        "print('=' * 70)\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('=' * 70)\n",
        "print('Starting up...')\n",
        "print('=' * 70)\n",
        "\n",
        "###########\n",
        "\n",
        "melody_chords_f1 = []\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "print('=' * 70)\n",
        "\n",
        "for i in tqdm(range(0, len(filez1), 16)):\n",
        "\n",
        "  with parallel_config(backend='threading', n_jobs=4, verbose = 0):\n",
        "\n",
        "    output = Parallel()(delayed(TMIDIX_MIDI_Processor)(f) for f in filez1[i:i+16])\n",
        "\n",
        "    for o in output:\n",
        "\n",
        "        if o is not None:\n",
        "            melody_chords_f1.append(o)\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FYlo5wYtcwYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (SAVE/LOAD ALL MIDI DATA)"
      ],
      "metadata": {
        "id": "CqVTZUGpc1oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save\n",
        "print('=' * 70)\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer([melody_chords_f, melody_chords_f1], '/content/B_CLassi_ALL_MIDI_DATA')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "id": "N8KInrPtc5cq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load\n",
        "print('=' * 70)\n",
        "melody_chords_f, melody_chords_f1 = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/B_CLassi_ALL_MIDI_DATA')\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "id": "Oitm3b6jfuhP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (PREP ALL MIDI DATA)"
      ],
      "metadata": {
        "id": "Y-RCeHP3dMb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prep data\n",
        "classifier_seq_length_in_notes = 640 # @param {type:\"slider\", min:128, max:2048, step:128}\n",
        "composition_sampling_steps_in_notes = 32 # @param {type:\"slider\", min:8, max:64, step:8}\n",
        "equalize_data_splits = True # @param {type:\"boolean\"}\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "SEQ_LEN = classifier_seq_length_in_notes # In notes\n",
        "STEP = composition_sampling_steps_in_notes # Composition sampling in notes\n",
        "EQUALIZE_DATA_SPLITS = equalize_data_splits # Balancing equalization\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "gdata = []\n",
        "bdata = []\n",
        "\n",
        "data = []\n",
        "\n",
        "good = 0\n",
        "bad = 0\n",
        "\n",
        "print('=' * 70)\n",
        "print('Prepping data...')\n",
        "print('=' * 70)\n",
        "\n",
        "# Good data == 1\n",
        "for m in tqdm(melody_chords_f):\n",
        "  for i in range(0, len(m[0]), STEP):\n",
        "    if len(m[0][i:i+SEQ_LEN]) == SEQ_LEN:\n",
        "      gdata.append([m[0][i:i+SEQ_LEN], [1]])\n",
        "      good += 1\n",
        "\n",
        "# Bad data == 0\n",
        "for m in tqdm(melody_chords_f1):\n",
        "  for i in range(0, len(m[0]), STEP):\n",
        "    if len(m[0][i:i+SEQ_LEN]) == SEQ_LEN:\n",
        "      bdata.append([m[0][i:i+SEQ_LEN], [0]])\n",
        "      bad += 1\n",
        "\n",
        "random.shuffle(gdata)\n",
        "random.shuffle(bdata)\n",
        "\n",
        "if EQUALIZE_DATA_SPLITS:\n",
        "  equal_data_size = min(len(gdata), len(bdata))\n",
        "  data = gdata[:equal_data_size] + bdata[:equal_data_size]\n",
        "  good = bad = equal_data_size\n",
        "\n",
        "else:\n",
        "  data = gdata + bdata\n",
        "\n",
        "random.shuffle(data)\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "print('Total data size:', len(data))\n",
        "print('Good data size:', good, '/', good / len(data))\n",
        "print('Bad data size:', bad, '/',  bad / len(data))\n",
        "print('Good to bad ratio:', good / bad)\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "id": "1ykiu7aedPDi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create training datasets and their splits\n",
        "training_batch_size = 32 # @param {type:\"slider\", min:4, max:128, step:4}\n",
        "train_dataset_size_ratio = 0.9 # @param {type:\"slider\", min:0.66, max:0.96, step:0.01}\n",
        "validation_dataset_size_ratio = 0.05 # @param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n",
        "test_dataset_size_ratio = 0.05 # @param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "BATCH_SIZE = training_batch_size\n",
        "\n",
        "TRAIN_DATASET_SIZE_RATIO = train_dataset_size_ratio\n",
        "VAL_DATASET_SIZE_RATIO = validation_dataset_size_ratio\n",
        "TEST_DATASET_SIZE_RATIO = test_dataset_size_ratio\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "def create_dataset(data, batch_size=16):\n",
        "    # Separate the features and labels\n",
        "    features = [lst[0] for lst in data]\n",
        "    labels = [lst[1][0] for lst in data]\n",
        "\n",
        "    # Convert the lists to TensorFlow tensors\n",
        "    tensor_features = tf.constant(features, dtype=tf.float32)\n",
        "    tensor_labels = tf.constant(labels, dtype=tf.int32)\n",
        "\n",
        "    # Create a tf.data.Dataset from the tensors\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((tensor_features, tensor_labels))\n",
        "\n",
        "    # Batch the dataset and discard incomplete batches\n",
        "    batched_dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "    return batched_dataset\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "print('=' * 70)\n",
        "print('Creating B Classi Training Datasets...')\n",
        "\n",
        "dataset = create_dataset(data, BATCH_SIZE)\n",
        "\n",
        "train_size = int(len(dataset) * TRAIN_DATASET_SIZE_RATIO)\n",
        "val_size = int(len(dataset) * TEST_DATASET_SIZE_RATIO)\n",
        "test_size = int(len(dataset) * VAL_DATASET_SIZE_RATIO)\n",
        "\n",
        "train = dataset.take(train_size)\n",
        "val = dataset.skip(train_size).take(val_size)\n",
        "test = dataset.skip(train_size+val_size).take(test_size)\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "id": "erI_2zPjR1m1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (CREATE MODEL)"
      ],
      "metadata": {
        "id": "YtD6yAh9Y3_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create the model\n",
        "model_size = 1024 # @param {type:\"slider\", min:512, max:2048, step:512}\n",
        "model_dropout = 0.5 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "model_kernel_size = 4 # @param {type:\"slider\", min:2, max:16, step:2}\n",
        "model_pool_size = 2 # @param {type:\"slider\", min:2, max:8, step:1}\n",
        "\n",
        "#=======================================================\n",
        "\n",
        "MODEL_SIZE = model_size\n",
        "DROPOUT = model_dropout\n",
        "KERNEL_SIZE = model_kernel_size\n",
        "POOL_SIZE = model_pool_size\n",
        "\n",
        "#=======================================================\n",
        "\n",
        "print('=' * 70)\n",
        "print('Creating model...')\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Add a Conv1D layer\n",
        "model.add(layers.Conv1D(MODEL_SIZE, KERNEL_SIZE, 1, activation='relu', input_shape=(SEQ_LEN, 1)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(DROPOUT))\n",
        "\n",
        "# Add a MaxPooling layer\n",
        "model.add(layers.MaxPooling1D(pool_size=POOL_SIZE))\n",
        "\n",
        "# Add a Conv1D layer\n",
        "model.add(layers.Conv1D(int(MODEL_SIZE // 2), KERNEL_SIZE, 1, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(DROPOUT))\n",
        "\n",
        "# Add a MaxPooling layer\n",
        "model.add(layers.MaxPooling1D(pool_size=POOL_SIZE))\n",
        "\n",
        "# Add a Conv1D layer\n",
        "model.add(layers.Conv1D(int(MODEL_SIZE // 4), KERNEL_SIZE, 1, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(DROPOUT))\n",
        "\n",
        "# Add a MaxPooling layer\n",
        "model.add(layers.MaxPooling1D(pool_size=POOL_SIZE))\n",
        "\n",
        "# Add a Conv1D layer\n",
        "model.add(layers.Conv1D(int(MODEL_SIZE // 8), KERNEL_SIZE, 1, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(DROPOUT))\n",
        "\n",
        "# Add a MaxPooling layer\n",
        "model.add(layers.MaxPooling1D(pool_size=POOL_SIZE))\n",
        "\n",
        "# Add a Conv1D layer\n",
        "model.add(layers.Conv1D(int(MODEL_SIZE // 16), KERNEL_SIZE, 1, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(DROPOUT))\n",
        "\n",
        "# Add a MaxPooling layer\n",
        "model.add(layers.MaxPooling1D(pool_size=POOL_SIZE))\n",
        "\n",
        "# Add a Flatten layer\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(MODEL_SIZE, activation='relu'))\n",
        "model.add(layers.Dropout(DROPOUT))\n",
        "\n",
        "# Add a Dense layer\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Tensorboard\n",
        "logdir='LOGS'\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# Add early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "\n",
        "model.summary()\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zlKtZ8gLrOk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C10kKcgxAIgK"
      },
      "source": [
        "# (TRAIN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train the model\n",
        "number_of_training_epochs = 10 # @param {type:\"slider\", min:1, max:15, step:1}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Training...Please wait...')\n",
        "print('=' * 70)\n",
        "\n",
        "hist = model.fit(train, validation_data=val, batch_size=BATCH_SIZE, epochs=number_of_training_epochs, callbacks=[es_callback, tensorboard_callback])\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "id": "Gcjg-rQAMINT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5VQ85GIAIgL"
      },
      "source": [
        "# (PLOT TRAINING RESULTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nVncS2KAIgL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Plot performance\n",
        "\n",
        "print('=' * 70)\n",
        "print('Plotting training results...')\n",
        "print('=' * 70)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "print('=' * 70)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcEkAnhyAIgL"
      },
      "source": [
        "# (EVAL MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG53-CCiAIgV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Eval model\n",
        "\n",
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = BinaryAccuracy()\n",
        "\n",
        "print('=' * 70)\n",
        "print('Evaluating model...')\n",
        "print('=' * 70)\n",
        "\n",
        "for batch in tqdm(test):\n",
        "    X, y = batch\n",
        "    yhat = model.predict(X, verbose=0)\n",
        "    pre.update_state(y, yhat)\n",
        "    re.update_state(y, yhat)\n",
        "    acc.update_state(y, yhat)\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "print('Model Precision:', pre.result().numpy())\n",
        "print('Model Recall:', re.result().numpy())\n",
        "print('Model Accuracy:', acc.result().numpy())\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BxismJoAIgW"
      },
      "source": [
        "# (SAVE/LOAD MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save model\n",
        "\n",
        "print('=' * 70)\n",
        "print('Saving model...')\n",
        "model.save(os.path.join('/content','B_CLassi_Pre_Trained_Model_' + str(round(pre.result().numpy(), 4)) + '_Precision' + '.keras'))\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eJQlCiVF56NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load model\n",
        "full_path_to_trained_model = \"/content/B_CLassi_Pre_Trained_Model_0.9942_Precision.keras\" # @param {type:\"string\"}\n",
        "print('=' * 70)\n",
        "print('Loading model...')\n",
        "model = load_model(full_path_to_trained_model)\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4LaD52gb-O8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z68PfuXhAIgV"
      },
      "source": [
        "# (CLASSIFY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (CUSTOM MIDI FILE)"
      ],
      "metadata": {
        "id": "CBlYXYvhvyDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load custom MIDI\n",
        "full_path_to_custom_MIDI_file = \"/content/B-CLassi/Come To My Window.mid\" # @param {type:\"string\"}\n",
        "sampling_step_in_notes = 32 # @param {type:\"slider\", min:8, max:128, step:8}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading custom MIDI file...')\n",
        "print('=' * 70)\n",
        "\n",
        "#=======================================================\n",
        "# START PROCESSING\n",
        "\n",
        "test_midi = [TMIDIX_MIDI_Processor(full_path_to_custom_MIDI_file)]\n",
        "\n",
        "test_data = []\n",
        "\n",
        "# Good data == 1\n",
        "for m in tqdm(test_midi):\n",
        "  for i in range(0, len(m[0]), sampling_step_in_notes):\n",
        "    if len(m[0][i:i+SEQ_LEN]) == SEQ_LEN:\n",
        "      test_data.append(m[0][i:i+SEQ_LEN])\n",
        "\n",
        "# Separate the features and labels\n",
        "features = [lst for lst in test_data]  # Corrected this line\n",
        "\n",
        "# Convert the lists to TensorFlow tensors\n",
        "tensor_features = tf.constant(features, dtype=tf.float32)\n",
        "\n",
        "# Create a tf.data.Dataset from the tensors\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(tensor_features)\n",
        "\n",
        "# Batch the dataset and discard incomplete batches\n",
        "batched_test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eipQ24Ubgifk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKHN9iwZAIgW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Classify\n",
        "good_classification_threshold = 0.5 # @param {type:\"slider\", min:0.1, max:1, step:0.05}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Classifying...')\n",
        "print('-' * 70)\n",
        "\n",
        "yhat = model.predict(batched_test_dataset)\n",
        "\n",
        "avg_label = round(sum([y[0] for y in yhat.tolist()]) / len(yhat.tolist()), 4)\n",
        "\n",
        "print('=' * 70)\n",
        "\n",
        "if avg_label > good_classification_threshold:\n",
        "    print(f'Predicted class is GOOD')\n",
        "else:\n",
        "    print(f'Predicted class is BAD')\n",
        "\n",
        "print('=' * 70)\n",
        "print('First five labels:', [round(y[0], 4) for y in yhat.tolist() if y[0] >= good_classification_threshold][:5])\n",
        "print('=' * 70)\n",
        "print('Total number of classification labels:', len(yhat.tolist()))\n",
        "print('=' * 70)\n",
        "print('TOtal number of good classification labels:', len([y[0] for y in yhat.tolist() if y[0] >= good_classification_threshold]))\n",
        "print('TOtal number of bad classification labels:', len([y[0] for y in yhat.tolist() if y[0] < good_classification_threshold]))\n",
        "print('=' * 70)\n",
        "print('Min/Max classification labels:', round(min(yhat.tolist())[0], 4), '/', round(max(yhat.tolist())[0], 4))\n",
        "print('=' * 70)\n",
        "print('Average classification label:', round(avg_label, 4))\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (CUSTOM MIDI DATASET)"
      ],
      "metadata": {
        "id": "ZAOIT97PwZo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save file list\n",
        "\n",
        "#@markdown Upload your custom MIDI dataset into EVAL_IN directory\n",
        "\n",
        "###########\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/EVAL_IN\"\n",
        "\n",
        "# os.chdir(dataset_addr)\n",
        "filez2 = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez2 += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if not filez2:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "else:\n",
        "  print('Randomizing file list...')\n",
        "  random.shuffle(filez2)\n",
        "  print('Done!')\n",
        "  print('=' * 70)\n",
        "  print('Total files:', len(filez2))\n",
        "  print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wvM9Dw0QwYx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process MIDIs with TMIDIX MIDI processor\n",
        "sampling_step_in_notes = 32 # @param {type:\"slider\", min:8, max:128, step:8}\n",
        "\n",
        "print('=' * 70)\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('=' * 70)\n",
        "print('Starting up...')\n",
        "print('=' * 70)\n",
        "\n",
        "###########\n",
        "\n",
        "melody_chords_f = []\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "print('=' * 70)\n",
        "\n",
        "for i in tqdm(range(0, len(filez2), 16)):\n",
        "\n",
        "  with parallel_config(backend='threading', n_jobs=4, verbose = 0):\n",
        "\n",
        "    output = Parallel()(delayed(TMIDIX_MIDI_Processor)(f) for f in filez2[i:i+16])\n",
        "\n",
        "    for o in output:\n",
        "\n",
        "        if o is not None:\n",
        "            melody_chords_f.append(o)\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "print('Finalizng MIDI data...')\n",
        "print('=' * 70)\n",
        "\n",
        "all_test_data = []\n",
        "\n",
        "for m in tqdm(melody_chords_f):\n",
        "  test_data = []\n",
        "  for i in range(0, len(m[0]), sampling_step_in_notes):\n",
        "    if len(m[0][i:i+SEQ_LEN]) == SEQ_LEN:\n",
        "      test_data.append(m[0][i:i+SEQ_LEN])\n",
        "  if test_data:\n",
        "    all_test_data.append([test_data, m[1]])\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "print('Total number of processed files:', len(all_test_data))\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vjGp7Cwbwmr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (SAVE/LOAD CUSTMO MIDI DATASET DATA)"
      ],
      "metadata": {
        "id": "8zrMJLre1F3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save\n",
        "print('=' * 70)\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(all_test_data, '/content/B_CLassi_CUSTOM_MIDI_DATASET_DATA')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nDCJm3JC08UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load\n",
        "print('=' * 70)\n",
        "all_test_data = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/B_CLassi_CUSTOM_MIDI_DATASET_DATA')\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rJIyCdAF0-7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Classify\n",
        "good_classification_threshold = 0.5 # @param {type:\"slider\", min:0.1, max:1, step:0.05}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Classifying...')\n",
        "print('=' * 70)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for a in tqdm(all_test_data):\n",
        "\n",
        "  features = [lst for lst in a[0]]  # Corrected this line\n",
        "  tensor_features = tf.constant(features, dtype=tf.float32)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices(tensor_features)\n",
        "  batched_test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "  yhat = model.predict(batched_test_dataset, verbose=0)\n",
        "\n",
        "  yhat_list = [y[0] for y in yhat.tolist()]\n",
        "\n",
        "  avg_label = round((sum(yhat_list) / len(yhat_list)), 4)\n",
        "  min_label, max_label = round(min(yhat_list), 4), round(max(yhat_list), 4)\n",
        "\n",
        "  if avg_label > 0.5:\n",
        "    good_or_bad = 1\n",
        "\n",
        "  else:\n",
        "    good_or_bad = 0\n",
        "\n",
        "  predictions.append([a[1], good_or_bad, avg_label, min_label, max_label])\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "print('Total number of classified MIDI:', len(predictions))\n",
        "print('=' * 70)\n",
        "print('TOtal number of good MIDIs:', len([y[1] for y in predictions if y[1] >= good_classification_threshold]))\n",
        "print('TOtal number of bad MIDIs:', len([y[1] for y in predictions if y[1] < good_classification_threshold]))\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lqSF3ZdLyUTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Copy classified MIDI splits into the output dir (EVAL_OUT)\n",
        "good_classification_threshold = 0.5 # @param {type:\"slider\", min:0.1, max:1, step:0.05}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Copying...')\n",
        "print('=' * 70)\n",
        "\n",
        "GOOD_THRESHOLD = good_classification_threshold\n",
        "\n",
        "good = 0\n",
        "bad = 0\n",
        "\n",
        "for p in tqdm(predictions):\n",
        "\n",
        "  src = '/content/EVAL_IN/' + p[0]\n",
        "\n",
        "  if p[2] > GOOD_THRESHOLD:\n",
        "    dest = '/content/EVAL_OUT/GOOD/' + p[0]\n",
        "    good += 1\n",
        "  else:\n",
        "    dest = '/content/EVAL_OUT/BAD/' + p[0]\n",
        "    bad += 1\n",
        "\n",
        "\n",
        "  shutil.copy2(src, dest)\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "print('Good/bad files count:', good, '/', bad)\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sz9qsI55M5si"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}