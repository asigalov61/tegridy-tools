{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "# ByteDance Piano Transcription (Ver 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "## https://github.com/bytedance/piano_transcription\n",
        "\n",
        "## https://github.com/azuwis/pianotrans\n",
        "\n",
        "***\n",
        "\n",
        "### Project Los Angeles\n",
        "### Tegridy Code 2023\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "X7JFKeW7HTr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (SETUP ENVIRONMENT)"
      ],
      "metadata": {
        "id": "MFc-x5DvH_4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install dependencies\n",
        "!pip install librosa==0.8.1\n",
        "!pip install piano_transcription_inference"
      ],
      "metadata": {
        "id": "cirk7Velwb6W",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (TRANSCRIBE)\n",
        "\n",
        "## 1) The first run may take a long time due to the model being downloaded from Zenodo which is quite slow usually\n",
        "\n",
        "## 2) Input audio must be in WAV format"
      ],
      "metadata": {
        "id": "4wd0mKVoH1dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Transcribe\n",
        "full_path_to_input_WAV = \"/content/input.wav\" # @param {type:\"string\"}\n",
        "full_path_to_output_MIDI = \"/content/output.mid\" # @param {type:\"string\"}\n",
        "\n",
        "from piano_transcription_inference import PianoTranscription, sample_rate, load_audio\n",
        "\n",
        "# Load audio\n",
        "(audio, _) = load_audio(full_path_to_input_WAV, sr=sample_rate, mono=True)\n",
        "\n",
        "# Transcriptor\n",
        "transcriptor = PianoTranscription(device='cuda')    # 'cuda' | 'cpu'\n",
        "\n",
        "# Transcribe and write out to MIDI file\n",
        "transcribed_dict = transcriptor.transcribe(audio, full_path_to_output_MIDI)"
      ],
      "metadata": {
        "id": "laaR9o9nwDzt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Congrats! You did it! :)"
      ],
      "metadata": {
        "id": "0jKlAwVHH4G4"
      }
    }
  ]
}